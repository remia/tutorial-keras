{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.chdir(os.path.join(os.getcwd(), 'chapter8'))\n",
    "    print(os.getcwd())\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0008,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "                      loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 10s 0us/step\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator loss : 0.6846811\n",
      "Adversarial loss : 0.66273654\n",
      "Discriminator loss : 0.7849399\n",
      "Adversarial loss : 4.353252\n",
      "Discriminator loss : 0.85142136\n",
      "Adversarial loss : 1.2609822\n",
      "Discriminator loss : 0.6811207\n",
      "Adversarial loss : 0.7681147\n",
      "Discriminator loss : 0.6848916\n",
      "Adversarial loss : 0.7525631\n",
      "Discriminator loss : 0.682313\n",
      "Adversarial loss : 0.7641295\n",
      "Discriminator loss : 0.6947319\n",
      "Adversarial loss : 0.808232\n",
      "Discriminator loss : 0.70643544\n",
      "Adversarial loss : 0.740895\n",
      "Discriminator loss : 0.7017917\n",
      "Adversarial loss : 0.73161954\n",
      "Discriminator loss : 0.6838856\n",
      "Adversarial loss : 0.7443297\n",
      "Discriminator loss : 0.6927617\n",
      "Adversarial loss : 0.75618684\n",
      "Discriminator loss : 0.7056594\n",
      "Adversarial loss : 0.74272776\n",
      "Discriminator loss : 0.7017482\n",
      "Adversarial loss : 0.8797337\n",
      "Discriminator loss : 0.6917359\n",
      "Adversarial loss : 0.7592901\n",
      "Discriminator loss : 0.687125\n",
      "Adversarial loss : 0.7454222\n",
      "Discriminator loss : 0.69563955\n",
      "Adversarial loss : 0.746019\n",
      "Discriminator loss : 0.68420964\n",
      "Adversarial loss : 0.7452483\n",
      "Discriminator loss : 0.7020935\n",
      "Adversarial loss : 0.78205836\n",
      "Discriminator loss : 0.69088924\n",
      "Adversarial loss : 0.74741066\n",
      "Discriminator loss : 0.6907493\n",
      "Adversarial loss : 0.8225387\n",
      "Discriminator loss : 0.68958724\n",
      "Adversarial loss : 0.7523348\n",
      "Discriminator loss : 0.690072\n",
      "Adversarial loss : 0.7723536\n",
      "Discriminator loss : 0.6960291\n",
      "Adversarial loss : 0.7430906\n",
      "Discriminator loss : 0.7398242\n",
      "Adversarial loss : 0.8783159\n",
      "Discriminator loss : 0.71561694\n",
      "Adversarial loss : 0.7588006\n",
      "Discriminator loss : 0.7043159\n",
      "Adversarial loss : 0.8787352\n",
      "Discriminator loss : 0.6880691\n",
      "Adversarial loss : 0.7423126\n",
      "Discriminator loss : 0.7127043\n",
      "Adversarial loss : 0.7325917\n",
      "Discriminator loss : 0.6835721\n",
      "Adversarial loss : 0.76710606\n",
      "Discriminator loss : 0.6808159\n",
      "Adversarial loss : 0.769885\n",
      "Discriminator loss : 0.69359815\n",
      "Adversarial loss : 0.7323359\n",
      "Discriminator loss : 0.7080917\n",
      "Adversarial loss : 0.75195163\n",
      "Discriminator loss : 0.6932801\n",
      "Adversarial loss : 0.7344402\n",
      "Discriminator loss : 0.6867194\n",
      "Adversarial loss : 0.7210817\n",
      "Discriminator loss : 0.692315\n",
      "Adversarial loss : 0.7392082\n",
      "Discriminator loss : 0.6998552\n",
      "Adversarial loss : 0.7018406\n",
      "Discriminator loss : 0.6888103\n",
      "Adversarial loss : 0.73935825\n",
      "Discriminator loss : 0.6910325\n",
      "Adversarial loss : 0.77352744\n",
      "Discriminator loss : 0.6887184\n",
      "Adversarial loss : 0.7625916\n",
      "Discriminator loss : 0.685376\n",
      "Adversarial loss : 0.7735332\n",
      "Discriminator loss : 0.69234645\n",
      "Adversarial loss : 0.68195945\n",
      "Discriminator loss : 0.6868679\n",
      "Adversarial loss : 0.74190676\n",
      "Discriminator loss : 0.6969012\n",
      "Adversarial loss : 0.7242098\n",
      "Discriminator loss : 0.69575304\n",
      "Adversarial loss : 0.7363483\n",
      "Discriminator loss : 0.6959324\n",
      "Adversarial loss : 0.76814824\n",
      "Discriminator loss : 0.6850737\n",
      "Adversarial loss : 0.7632411\n",
      "Discriminator loss : 0.69265306\n",
      "Adversarial loss : 0.7719042\n",
      "Discriminator loss : 0.68192935\n",
      "Adversarial loss : 0.8121354\n",
      "Discriminator loss : 0.7373947\n",
      "Adversarial loss : 0.71038926\n",
      "Discriminator loss : 0.71115744\n",
      "Adversarial loss : 0.726069\n",
      "Discriminator loss : 0.68325675\n",
      "Adversarial loss : 0.7000865\n",
      "Discriminator loss : 0.6888227\n",
      "Adversarial loss : 0.42289996\n",
      "Discriminator loss : 1.1817648\n",
      "Adversarial loss : 0.775354\n",
      "Discriminator loss : 0.6997593\n",
      "Adversarial loss : 0.7378439\n",
      "Discriminator loss : 0.68461627\n",
      "Adversarial loss : 0.7196603\n",
      "Discriminator loss : 0.6914588\n",
      "Adversarial loss : 0.7561568\n",
      "Discriminator loss : 0.6798882\n",
      "Adversarial loss : 0.7623259\n",
      "Discriminator loss : 0.69761854\n",
      "Adversarial loss : 0.7820774\n",
      "Discriminator loss : 0.7776599\n",
      "Adversarial loss : 0.8078699\n",
      "Discriminator loss : 0.6951933\n",
      "Adversarial loss : 0.76128775\n",
      "Discriminator loss : 0.6930481\n",
      "Adversarial loss : 0.7493617\n",
      "Discriminator loss : 0.61488867\n",
      "Adversarial loss : 3.2663817\n",
      "Discriminator loss : 0.70422554\n",
      "Adversarial loss : 0.8203886\n",
      "Discriminator loss : 0.7487625\n",
      "Adversarial loss : 0.7963377\n",
      "Discriminator loss : 0.690004\n",
      "Adversarial loss : 0.75003636\n",
      "Discriminator loss : 0.68402445\n",
      "Adversarial loss : 0.7562204\n",
      "Discriminator loss : 0.6891632\n",
      "Adversarial loss : 0.7193501\n",
      "Discriminator loss : 0.6993869\n",
      "Adversarial loss : 0.77834713\n",
      "Discriminator loss : 0.6889219\n",
      "Adversarial loss : 0.7473637\n",
      "Discriminator loss : 0.6975047\n",
      "Adversarial loss : 0.7659771\n",
      "Discriminator loss : 0.7038922\n",
      "Adversarial loss : 0.7437725\n",
      "Discriminator loss : 0.6947009\n",
      "Adversarial loss : 0.76190865\n",
      "Discriminator loss : 0.67804563\n",
      "Adversarial loss : 0.7941841\n",
      "Discriminator loss : 0.6979858\n",
      "Adversarial loss : 0.7670172\n",
      "Discriminator loss : 0.69570315\n",
      "Adversarial loss : 0.7525226\n",
      "Discriminator loss : 0.68013203\n",
      "Adversarial loss : 0.75267136\n",
      "Discriminator loss : 0.7059201\n",
      "Adversarial loss : 0.7319926\n",
      "Discriminator loss : 0.6900962\n",
      "Adversarial loss : 0.74758744\n",
      "Discriminator loss : 0.70691645\n",
      "Adversarial loss : 0.7356211\n",
      "Discriminator loss : 0.6904838\n",
      "Adversarial loss : 0.6698704\n",
      "Discriminator loss : 0.70843184\n",
      "Adversarial loss : 0.84485734\n",
      "Discriminator loss : 0.6860063\n",
      "Adversarial loss : 0.59800506\n",
      "Discriminator loss : 0.6908105\n",
      "Adversarial loss : 0.7512127\n",
      "Discriminator loss : 0.68219936\n",
      "Adversarial loss : 0.7595116\n",
      "Discriminator loss : 0.6966537\n",
      "Adversarial loss : 0.6175312\n",
      "Discriminator loss : 0.68731713\n",
      "Adversarial loss : 0.7270447\n",
      "Discriminator loss : 0.700359\n",
      "Adversarial loss : 0.7653393\n",
      "Discriminator loss : 0.701156\n",
      "Adversarial loss : 0.793194\n",
      "Discriminator loss : 0.7494806\n",
      "Adversarial loss : 0.78751796\n",
      "Discriminator loss : 0.69848526\n",
      "Adversarial loss : 0.7569032\n",
      "Discriminator loss : 0.6746907\n",
      "Adversarial loss : 0.7393974\n",
      "Discriminator loss : 0.7018967\n",
      "Adversarial loss : 0.72734463\n",
      "Discriminator loss : 0.7203186\n",
      "Adversarial loss : 1.1434815\n",
      "Discriminator loss : 0.66669905\n",
      "Adversarial loss : 0.9044442\n",
      "Discriminator loss : 0.69518775\n",
      "Adversarial loss : 0.7839054\n",
      "Discriminator loss : 0.7024743\n",
      "Adversarial loss : 0.8132409\n",
      "Discriminator loss : 0.71574414\n",
      "Adversarial loss : 0.88746154\n",
      "Discriminator loss : 0.6953719\n",
      "Adversarial loss : 0.7837996\n",
      "Discriminator loss : 0.68187255\n",
      "Adversarial loss : 0.851217\n",
      "Discriminator loss : 0.69189614\n",
      "Adversarial loss : 0.8870896\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],) +\n",
    "    (height, width, channels)).astype('float32') / 255.\n",
    "\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = '.'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,\n",
    "                                             latent_dim))\n",
    "\n",
    "    generated_image = generator.predict(random_latent_vectors)\n",
    "\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_image, real_images])\n",
    "\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                             np.zeros((batch_size, 1))])\n",
    "    labels  += 0.05 * np.random.random(labels.shape)\n",
    "\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,\n",
    "                                             latent_dim))\n",
    "\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors,\n",
    "                                misleading_targets)\n",
    "\n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "\n",
    "        print('Discriminator loss :', d_loss)\n",
    "        print('Adversarial loss :', a_loss)\n",
    "\n",
    "        img = image.array_to_img(generated_image[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
    "\n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='generated_frog9900.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='real_frog9900.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
